{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6217e043-f9a9-45a5-b96d-948e0a524ae0",
      "metadata": {
        "id": "6217e043-f9a9-45a5-b96d-948e0a524ae0"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c20e3ee6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c20e3ee6",
        "outputId": "1b9dc19d-6e62-421c-fbc9-d7a3143b7752"
      },
      "outputs": [],
      "source": [
        "# Запустить установку mne, если не установлена в VSCode\n",
        "#! pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "34043483-12fa-47df-af9a-e9975e2ebe6e",
      "metadata": {
        "id": "34043483-12fa-47df-af9a-e9975e2ebe6e"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "#import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# библиотека взаимодействия с интерпретатором\n",
        "import sys\n",
        "if not sys.warnoptions:\n",
        "    import warnings\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "\n",
        "# Все исходные файлы размещены в PATH\n",
        "PATH = '' ## /content/drive/MyDrive/.../\n",
        "\n",
        "# Папка для сохранения весов лучшей модели при обучении (исп-ся в ModelCheckpoint в функции callbacks)\n",
        "PATH_FOR_MODEL = 'lstm_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "vVnS2sgjJXT-",
      "metadata": {
        "id": "vVnS2sgjJXT-"
      },
      "outputs": [],
      "source": [
        "def read_data(path_to_zip):\n",
        "    mounts = {\n",
        "        1 : {\n",
        "            'path_X_train' : 'X_train_1.npy',\n",
        "            'path_y_train' : 'y_train_1.npy',\n",
        "            'path_X_test_dataset' : 'X_test_dataset_1.pkl',\n",
        "        },\n",
        "        2 : {\n",
        "            'path_X_train' : 'X_train_2.npy',\n",
        "            'path_y_train' : 'y_train_2.npy',\n",
        "            'path_X_test_dataset' : 'X_test_dataset_2.pkl',\n",
        "        },\n",
        "        3 : {\n",
        "            'path_X_train' : 'X_train_3.npy',\n",
        "            'path_y_train' : 'y_train_3.npy',\n",
        "            'path_X_test_dataset' : 'X_test_dataset_3.pkl',\n",
        "        }\n",
        "    }\n",
        "\n",
        "    SFREQ = 1000.0 / 33\n",
        "\n",
        "    for mount_name, mount in mounts.items():\n",
        "        mount['X_train'] = np.load(path_to_zip)[mount['path_X_train']]\n",
        "        mount['y_train'] = np.load(path_to_zip)[mount['path_y_train']]\n",
        "        with ZipFile(path_to_zip) as myzip:\n",
        "            with myzip.open(mount['path_X_test_dataset']) as myfile:\n",
        "                mount['X_test_dataset'] = pickle.load(myfile)\n",
        "        \n",
        "        X_train = mount['X_train'] \n",
        "        y_train = mount['y_train']\n",
        "        \n",
        "        raw = mne.io.RawArray(\n",
        "            data=X_train.T,\n",
        "            info=mne.create_info(\n",
        "                ch_names=list(np.arange(X_train.shape[1]).astype(str)),\n",
        "                sfreq=SFREQ,\n",
        "                ch_types='eeg'\n",
        "            )\n",
        "        )\n",
        "        raw_y = mne.io.RawArray(\n",
        "            data=y_train.reshape(1,-1),\n",
        "            info=mne.create_info(\n",
        "                ch_names=['y'],\n",
        "                sfreq=SFREQ,\n",
        "                ch_types='misc'\n",
        "            )\n",
        "        )\n",
        "        raw = raw.add_channels([raw_y])\n",
        "        \n",
        "        events = np.where(np.abs(np.diff(y_train)) > 0)[0]\n",
        "\n",
        "        events = np.stack([\n",
        "            events,\n",
        "            np.zeros_like(events),\n",
        "            np.zeros_like(events)\n",
        "        ], axis=1)\n",
        "        \n",
        "        epochs = mne.Epochs(\n",
        "            raw,\n",
        "            events=events,\n",
        "            tmin=-1, \n",
        "            tmax=1*2.5, \n",
        "            preload=True,\n",
        "            baseline=None,\n",
        "            picks='all'\n",
        "        )\n",
        "        \n",
        "        X_train_nn = epochs.copy().pick_types(eeg =True)._data.swapaxes(1, 2)\n",
        "        mount['X_train_nn'] = X_train_nn\n",
        "\n",
        "    return mounts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "hV48rPuZU_zE",
      "metadata": {
        "id": "hV48rPuZU_zE"
      },
      "outputs": [],
      "source": [
        "def read_y_test(path_to_zip):\n",
        "    # Чтение sample_submission.csv из архива\n",
        "    with ZipFile(path_to_zip) as myzip:\n",
        "        y_test = pd.read_csv(myzip.open('sample_submission.csv'))\n",
        "\n",
        "    y_test[['subject_id', 'sample', 'timestep']] = (\n",
        "        y_test['subject_id-sample-timestep']\n",
        "        .str.split('-', 2, expand=True)\n",
        "        .astype(int)\n",
        "    )\n",
        "    return y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9yQjbqhQKLUy",
      "metadata": {
        "id": "9yQjbqhQKLUy"
      },
      "outputs": [],
      "source": [
        "# Функция для расчета метрики f1_score, Precision, Recall\n",
        "# Примечание: Metrics have been removed from Keras core on 2.0 version\n",
        "# https://stackoverflow.com/questions/66554207/calculating-micro-f-1-score-in-keras\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Recall metric.\n",
        "        Only computes a batch-wise average of recall.\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Precision metric.\n",
        "        Only computes a batch-wise average of precision.\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true*y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives/(predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision + recall + K.epsilon()))\n",
        "\n",
        "# Callbacks that used for training model\n",
        "def callbacks(lr, num_train):\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        os.path.join(PATH_BEST_MODEL, 'best_model_rnn_' + str(num_train) + '.hdf5'), \n",
        "        monitor='val_f1', \n",
        "        verbose=1, \n",
        "        mode='max', \n",
        "        save_best_only=True\n",
        "    )\n",
        "\n",
        "    earlystop = EarlyStopping(\n",
        "        monitor='val_f1', \n",
        "        mode='max', \n",
        "        patience=150, \n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_f1', \n",
        "        mode='max', \n",
        "        factor=0.9, \n",
        "        patience=15, # можно 10\n",
        "        verbose=1, \n",
        "        min_lr=lr/10000\n",
        "    )\n",
        "    \n",
        "    return [checkpoint, earlystop, reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "YFBMaJvNP2U2",
      "metadata": {
        "id": "YFBMaJvNP2U2"
      },
      "outputs": [],
      "source": [
        "def add_prediction(mount, mount_name, y_test):\n",
        "    X_train_nn = mount['X_train_nn']\n",
        "    X_test_dataset = mount['X_test_dataset']\n",
        "    m_lstm = keras.models.load_model(os.path.join(PATH_FOR_MODEL, 'model_lstm_' + str(mount_name)), \n",
        "                                    custom_objects={\"f1\": f1})\n",
        "    m_lstm.predict(mount['X_train_nn'], verbose=0)\n",
        "    \n",
        "    y_pred_test_lstm = []\n",
        "\n",
        "    for i in range(len(X_test_dataset)):\n",
        "        X_test_i = np.expand_dims(X_test_dataset[i], axis=0).swapaxes(1, 2).astype(np.float64)\n",
        "        y_pred_test_lstm += [m_lstm.predict(X_test_i, verbose=0)]\n",
        "    \n",
        "    y_pred_test_lstm = [arr.argmax(axis=-1) for arr in y_pred_test_lstm]\n",
        "    print(len(y_pred_test_lstm))\n",
        "    assert len(y_pred_test_lstm) == y_test.query(\"subject_id == @mount_name\")['sample'].nunique()\n",
        "    \n",
        "    mount['y_pred_test_lstm'] = y_pred_test_lstm\n",
        "    return mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "iDUqo8ljKSmZ",
      "metadata": {
        "id": "iDUqo8ljKSmZ"
      },
      "outputs": [],
      "source": [
        "def make_embedding(mounts, y_test):\n",
        "    for mount_name, mount in mounts.items():\n",
        "        mount = add_prediction(mount, mount_name, y_test)\n",
        "\n",
        "    y_pred_test_res = []\n",
        "    \n",
        "    for mount_name, mount in mounts.items():\n",
        "        y_pred_test_res.extend(mount['y_pred_test_lstm'])\n",
        "    y_pred_test_res = np.concatenate(y_pred_test_res, axis=-1)[0]\n",
        "    \n",
        "    assert y_pred_test_res.shape[0] == y_test.shape[0]\n",
        "    \n",
        "    y_test_submit = y_test[['subject_id-sample-timestep', 'class']]\n",
        "    y_test_submit['class'] = y_pred_test_res\n",
        "    y_test_submit.to_csv('./y_test_submit_rnn_LSTM_embeded.csv', index=False)\n",
        "    return y_test_submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "dDkbtlJ3Q0i0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDkbtlJ3Q0i0",
        "outputId": "84d98516-8247-413e-e7e9-68ee3f301e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating RawArray with float64 data, n_channels=50, n_times=24030\n",
            "    Range : 0 ... 24029 =      0.000 ...   792.957 secs\n",
            "Ready.\n",
            "Creating RawArray with float64 data, n_channels=1, n_times=24030\n",
            "    Range : 0 ... 24029 =      0.000 ...   792.957 secs\n",
            "Ready.\n",
            "Not setting metadata\n",
            "277 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 277 events and 107 original time points ...\n",
            "1 bad epochs dropped\n",
            "Creating RawArray with float64 data, n_channels=50, n_times=23202\n",
            "    Range : 0 ... 23201 =      0.000 ...   765.633 secs\n",
            "Ready.\n",
            "Creating RawArray with float64 data, n_channels=1, n_times=23202\n",
            "    Range : 0 ... 23201 =      0.000 ...   765.633 secs\n",
            "Ready.\n",
            "Not setting metadata\n",
            "264 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 264 events and 107 original time points ...\n",
            "1 bad epochs dropped\n",
            "Creating RawArray with float64 data, n_channels=50, n_times=23177\n",
            "    Range : 0 ... 23176 =      0.000 ...   764.808 secs\n",
            "Ready.\n",
            "Creating RawArray with float64 data, n_channels=1, n_times=23177\n",
            "    Range : 0 ... 23176 =      0.000 ...   764.808 secs\n",
            "Ready.\n",
            "Not setting metadata\n",
            "268 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 268 events and 107 original time points ...\n",
            "1 bad epochs dropped\n",
            "899\n",
            "855\n",
            "861\n",
            "y_test_submit created\n"
          ]
        }
      ],
      "source": [
        "path_to_zip = os.path.join(PATH, 'data/motorica-advanced-gesture-classification.zip')\n",
        "mounts = read_data(path_to_zip)\n",
        "y_test = read_y_test(path_to_zip)\n",
        "y_test_submit = make_embedding(mounts, y_test)\n",
        "print('y_test_submit created')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
